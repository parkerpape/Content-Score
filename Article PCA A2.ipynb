{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb7af8c6-7418-44fa-bc3e-e85045c53cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time Frame  View Weight  Time Weight  Session Weight  Average View Totals  \\\n",
      "0     2023-12     0.477652     0.044679        0.477669         11926.675039   \n",
      "1     2024-01     0.484807     0.030384        0.484808         21184.437819   \n",
      "2     2024-02     0.483709     0.032577        0.483714          9267.572848   \n",
      "3     2024-03     0.476485     0.047005        0.476510          7802.551661   \n",
      "4     2024-04     0.485098     0.029782        0.485120         16102.551363   \n",
      "5     2024-05     0.472554     0.054830        0.472616         14582.269618   \n",
      "6     2024-06     0.475428     0.049135        0.475436         18323.387168   \n",
      "7     2024-07     0.484186     0.031612        0.484201         30492.968750   \n",
      "8     2024-08     0.494932     0.010132        0.494936         29561.986425   \n",
      "9     2024-09     0.473465     0.053087        0.473448         63357.560197   \n",
      "10    2024-10     0.498959     0.002083        0.498959         70499.257353   \n",
      "11    2024-11     0.440126     0.119705        0.440169         18846.755784   \n",
      "12    2024-12     0.436125     0.127739        0.436136         10830.907767   \n",
      "13    2025-01     0.459293     0.081355        0.459352         25854.102204   \n",
      "14    2025-02     0.480000     0.039923        0.480076         17714.917874   \n",
      "15    2025-03     0.474795     0.050338        0.474867         18348.384798   \n",
      "16    2025-04     0.442960     0.113923        0.443116         14970.751958   \n",
      "17    2025-05     0.449600     0.100726        0.449675         14161.819843   \n",
      "\n",
      "    Average Time Per View  Average Session Totals  \n",
      "0               28.997011            11066.221350  \n",
      "1               25.753595            19365.867121  \n",
      "2               31.110213             8558.956954  \n",
      "3               28.443259             7130.944649  \n",
      "4               27.395470            14708.169811  \n",
      "5               27.145795            13377.028169  \n",
      "6               28.691832            16949.274336  \n",
      "7               28.195963            27714.473558  \n",
      "8               25.286389            27140.110860  \n",
      "9               26.785668            57365.388206  \n",
      "10              33.451349            63475.215686  \n",
      "11              28.559356            17311.079692  \n",
      "12              28.093759             9996.320388  \n",
      "13              31.095694            23664.228457  \n",
      "14              30.598463            15947.782609  \n",
      "15              32.300770            16519.318290  \n",
      "16              31.388038            13592.480418  \n",
      "17              34.435654            12803.851175  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "pca_evaluation = pd.DataFrame({'Time Frame': [], 'View Weight': [], 'Time Weight': [], 'Session Weight': [], \n",
    "                               'Average View Totals': [], 'Average Time Per View': [], 'Average Session Totals': []})\n",
    "\n",
    "def run_pca(csv_file_pathway):\n",
    "    # Get file name\n",
    "    with open(csv_file_pathway, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    file_name = lines[0].strip().strip('\"')\n",
    "\n",
    "    # Load the data\n",
    "    csv_content = '\\n'.join(lines[3:])  # skip the first three rows\n",
    "    df = pd.read_csv(StringIO(csv_content), delimiter='\\t')\n",
    "\n",
    "    # Clean up columns\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.replace(r'[\"\\']', '', regex=True)\n",
    "        .str.replace(r'[,\\s]+$', '', regex=True)\n",
    "    )\n",
    "    \n",
    "    # Define columns\n",
    "    required_cols = [\n",
    "        \"CMS Url\",\n",
    "        \"View Quantity--All Users\",\n",
    "        \"Time Spent per View--All Users\",\n",
    "        \"Session Quantity--All Users\"\n",
    "    ]\n",
    "    \n",
    "    numeric_cols = [\n",
    "        \"View Quantity--All Users\",\n",
    "        \"Time Spent per View--All Users\",\n",
    "        \"Session Quantity--All Users\"\n",
    "    ]\n",
    "    \n",
    "    # Check for missing columns\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns in data: {missing_cols}\")\n",
    "\n",
    "    # Filter rows with required columns not null\n",
    "    df_clean = df.dropna(subset=required_cols)\n",
    "    if df_clean.empty:\n",
    "        raise ValueError(\"No rows left after dropping rows with missing required values.\")\n",
    "\n",
    "    # Convert numeric columns to numbers\n",
    "    for col in numeric_cols:\n",
    "        df_clean[col] = (\n",
    "            df_clean[col]\n",
    "            .astype(str)\n",
    "            .str.replace(r'[,\"\\']', '', regex=True)  # Remove commas, quotes\n",
    "            .str.strip()\n",
    "        )\n",
    "\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "    \n",
    "    # Drop rows with any NaNs in numeric columns\n",
    "    df_clean = df_clean.dropna(subset=numeric_cols)\n",
    "    if df_clean.empty:\n",
    "        raise ValueError(\"No rows left after converting numeric columns and dropping NaNs.\")\n",
    "\n",
    "    # Assert all numeric columns are positive\n",
    "    assert (df_clean[numeric_cols] >= 0).all().all(), \"All scores should be positive\"\n",
    "\n",
    "    # Calculate scores\n",
    "    df_clean[\"view_score\"] = df_clean[\"View Quantity--All Users\"] / (\n",
    "        df_clean[\"View Quantity--All Users\"].sum() / len(df_clean)\n",
    "    )\n",
    "    \n",
    "    df_clean[\"time_score\"] = df_clean[\"Time Spent per View--All Users\"] / (\n",
    "        df_clean[\"Time Spent per View--All Users\"].sum() / len(df_clean)\n",
    "    )\n",
    "    \n",
    "    df_clean[\"session_score\"] = df_clean[\"Session Quantity--All Users\"] / (\n",
    "        df_clean[\"Session Quantity--All Users\"].sum() / len(df_clean)\n",
    "    )\n",
    "    \n",
    "    # Drop rows with any NaNs in score columns\n",
    "    df_clean = df_clean.dropna(subset=['view_score', 'time_score', 'session_score']).copy()\n",
    "    assert (df_clean[['view_score', 'time_score', 'session_score']] >= 0).all().all(), \"All scores should be positive\"\n",
    "\n",
    "    # Standardize scores\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(df_clean[['view_score', 'time_score', 'session_score']])\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=1)\n",
    "    df_clean['pca_score_raw'] = pca.fit_transform(X)\n",
    "    \n",
    "    # Normalize PCA output to center around 1\n",
    "    mean_score = abs(df_clean['pca_score_raw']).mean()\n",
    "    df_clean['content_score'] = df_clean['pca_score_raw'] / mean_score\n",
    "    \n",
    "    # Extract component weights\n",
    "    weights_sum = abs(pca.components_[0]).sum()\n",
    "    view_weight = abs(pca.components_[0][0]) / weights_sum\n",
    "    time_weight = abs(pca.components_[0][1]) / weights_sum\n",
    "    session_weight = abs(pca.components_[0][2]) / weights_sum\n",
    "    \n",
    "    weights_dict = {\n",
    "        'Time Frame': file_name[31:],\n",
    "        'View Weight': view_weight,\n",
    "        'Time Weight': time_weight,\n",
    "        'Session Weight': session_weight,\n",
    "        'Average View Totals': df_clean[\"View Quantity--All Users\"].sum() / len(df_clean),\n",
    "        'Average Time Per View': df_clean[\"Time Spent per View--All Users\"].sum() / len(df_clean),\n",
    "        'Average Session Totals': df_clean[\"Session Quantity--All Users\"].sum() / len(df_clean)\n",
    "    }\n",
    "    \n",
    "    # Append the row to the DataFrame\n",
    "    global pca_evaluation\n",
    "    pca_evaluation = pd.concat([pca_evaluation, pd.DataFrame([weights_dict])], ignore_index=True)\n",
    "    \n",
    "# Loop through years and months\n",
    "for year, start_month, end_month in [\n",
    "    (2023, 12, 12),   # 2023-12 to 2023-12\n",
    "    (2024, 1, 12),   # 2024-01 to 2024-12\n",
    "    (2025, 1, 5)     # 2025-01 to 2025-05\n",
    "]: # Choose time range\n",
    "    for month in range(start_month, end_month + 1):\n",
    "        month_str = str(month).zfill(2)\n",
    "        run_pca(f'/Users/parker.pape/Projects/Content Score A2/Data Table - Raw Content Score A2 Variables {year}-{month_str}.csv')\n",
    "\n",
    "pca_evaluation.to_csv(\"/Users/parker.pape/Projects/Content Score A2/Article PCA A2 Output.csv\", index=False)\n",
    "\n",
    "print(pca_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a89f6c-797d-4c65-8a79-a5e793270e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
